receivers:
  otlp:
    protocols:
      grpc:

exporters:
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 10000
      # this should work out to about 8M batches/second for 10s buffer
  logging:
    loglevel: debug
  prometheus:
    endpoint: "0.0.0.0:1234"

processors:
  memory_limiter:
    check_interval: 1s
    limit_percentage: 30
    spike_limit_percentage: 6
  batch:
    timeout: 2s
    send_batch_max_size: 32768

extensions:
  memory_ballast:
    size_in_percentage: 10

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [jaeger]
